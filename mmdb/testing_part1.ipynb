{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # This is the in situ and SSS collocation code. \n",
    "# # this is the part A of the program that searches for L1R files that have any data where cruise is\n",
    "\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pyresample import image, geometry, load_area, save_quicklook, SwathDefinition, area_def2basemap\n",
    "from pyresample.kd_tree import resample_nearest\n",
    "from scipy import spatial\n",
    "\n",
    "sys.path.append('./subroutines/')\n",
    "from read_routines import read_usv, get_filelist_amsr2_l1r,get_orbital_data_amsr2\n",
    "\n",
    "# # Define a function to read in insitu data\n",
    "# - Read in the Saildrone USV file either from a local disc or using OpenDAP.\n",
    "# - add room to write collocated data to in situ dataset\n",
    "# input **********************************\n",
    "\n",
    "# ## First let's figure out what orbital files actually have data in our area of interest.  To do this, use the pyresample software\n",
    "#\n",
    "# - read in the in situ data\n",
    "# - calculate the in situ min/max dates to know what files to check\n",
    "#\n",
    "# Now we have our time of interest\n",
    "#\n",
    "# - loop through the satellite data\n",
    "# - calculate the in situ min/max lat/lon on the same day to define a small box of interest\n",
    "# - use pyresample to map the data onto a predefined 0.1 deg resolution spatial grid\n",
    "# - subset the gridded map to the area of interest\n",
    "# - see if there is any valid data in that area\n",
    "# - if there is any valid data, save the filename into a list\n",
    "#\n",
    "#\n",
    "'''some definitions'''\n",
    "area_def = load_area('areas.cfg', 'pc_world')\n",
    "rlon = np.arange(-180, 180, .1)\n",
    "rlat = np.arange(90, -90, -.1)\n",
    "\n",
    "input_iusv_start = 4 #int(input(\"Enter start cruise processing number 0-10: \"))\n",
    "input_iusv_end = 5 #int(input(\"Enter stop cruise processing number 0-10: \"))\n",
    "adir_usv = 'C:/Users/gentemann/Google Drive/public/2019_saildrone/' #str(input(\"Enter directory for USV data: \"))\n",
    "adir_l1r = 'F:/data/sat_data/smap/SSS/L2/JPL/V4.2/'#str(input(\"Enter directory for L1R data: \"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILEIN: C:/Users/gentemann/Google Drive/public/2019_saildrone/arctic_2019_sd1033-NRT-1_min-v1.nc\n",
      "2019-05-14T00:00:00.000000000 2019-05-14T03:20:00.000000000\n",
      "2019-05-14T00:00:00.000000000 numfiles: 0\n"
     ]
    }
   ],
   "source": [
    "#intialize grid\n",
    "for iusv in range(input_iusv_start,input_iusv_end):\n",
    "\n",
    "    file_save=[]  #initialize variable for each processing run\n",
    "\n",
    "    ds_usv,name_usv = read_usv(adir_usv,iusv)\n",
    "    fileout = adir_usv + 'mmdb_collocation_test/' + name_usv +'AMSR2MMDB_combined.nc'\n",
    "\n",
    "    #search usv data\n",
    "    minday,maxday = ds_usv.time[0],ds_usv.time[200]#ds_usv.time[-1]\n",
    "    usv_day = minday\n",
    "    print(minday.data,maxday.data)\n",
    "\n",
    "    while usv_day<=maxday:\n",
    "        #while looping through USV data, look at data +-1 day\n",
    "        ds_day = ds_usv.sel(time=slice(usv_day-np.timedelta64(1,'D'),usv_day+np.timedelta64(1,'D')))\n",
    "        ilen = ds_day.time.size\n",
    "        if ilen<1:   #don't run on days without any data\n",
    "            continue\n",
    "        minlon,maxlon,minlat,maxlat = ds_day.lon.min().data,ds_day.lon.max().data,ds_day.lat.min().data,ds_day.lat.max().data\n",
    "        #caluclate filelist ofr orbits on specific day\n",
    "        filelist = get_filelist_amsr2_l1r(adir_l1r, usv_day)\n",
    "\n",
    "        #the more recent data is in daily directories, so easy to search\n",
    "        #the older data, pre 2018 is in monthly directories so only search files for day\n",
    "        print(usv_day.data,'numfiles:',len(filelist))\n",
    "        x,y,z = [],[],[]\n",
    "        for file in filelist:\n",
    "            xlat,xlon,sat_time,var_data=get_orbital_data_amsr2(iusv,file)\n",
    "            x = xlon.data\n",
    "            y = xlat.data\n",
    "            z = var_data.data\n",
    "            lons,lats,data = x,y,z\n",
    "            swath_def = SwathDefinition(lons, lats)\n",
    "            result1 = resample_nearest(swath_def, data, area_def, radius_of_influence=20000, fill_value=None)\n",
    "            da = xr.DataArray(result1,name='sat_data',coords={'lat':rlat,'lon':rlon},dims=('lat','lon'))\n",
    "            subset = da.sel(lat = slice(maxlat,minlat),lon=slice(minlon,maxlon))\n",
    "            num_obs = np.isfinite(subset).sum()\n",
    "\n",
    "            if num_obs<1:  #no collocations so go to next orbit\n",
    "                continue\n",
    "\n",
    "            # drop points outside of box\n",
    "            usv_min_lon, usv_max_lon = ds_usv.lon.min().data - .5, ds_usv.lon.max().data + .5\n",
    "            usv_min_lat, usv_max_lat = ds_usv.lat.min().data - .5, ds_usv.lat.max().data + .5\n",
    "            cond = (xlon >= usv_min_lon) & (xlon <= usv_max_lon)\n",
    "            sub_lon = xlon.where(cond)\n",
    "            cond = (xlat >= usv_min_lat) & (xlat <= usv_max_lat)\n",
    "            sub_lat = xlat.where(cond)\n",
    "\n",
    "            ph0 = var_data.phony_dim_0\n",
    "            ph1 = var_data.phony_dim_1\n",
    "            tem_time = sat_time\n",
    "            ds = xr.Dataset({'time': (['phony_dim_0'], tem_time),\n",
    "                             'tb': (['phony_dim_0', 'phony_dim_1'], var_data.data),\n",
    "                             'lat': (['phony_dim_0', 'phony_dim_1'], sub_lat.data),\n",
    "                             'lon': (['phony_dim_0', 'phony_dim_1'], sub_lon.data)},\n",
    "                            coords={'phony_dim_0': (['phony_dim_0'], ph0),\n",
    "                                    'phony_dim_1': (['phony_dim_1'], ph1)})\n",
    "\n",
    "            #stack xarray dataset then drop lon == nan\n",
    "            ds2 = ds.stack(z=('phony_dim_0', 'phony_dim_1')).reset_index('z')\n",
    "            #drop nan\n",
    "            ds_dropa = ds2.where(np.isfinite(ds2.lon), drop=True)\n",
    "            ds_drop = ds_dropa.where(np.isfinite(ds_dropa.lat), drop=True)\n",
    "\n",
    "            lats = ds_drop.lat.data\n",
    "            lons = ds_drop.lon.data\n",
    "            inputdata = list(zip(lons.ravel(), lats.ravel()))\n",
    "            tree = spatial.KDTree(inputdata)\n",
    "            orbit_time = ds.time.max().data - np.timedelta64(1, 'D')\n",
    "            orbit_time2 = ds.time.max().data + np.timedelta64(1, 'D')\n",
    "            usv_subset = ds_usv.sel(time=slice(orbit_time, orbit_time2))\n",
    "            ilen = ds_usv.time.size\n",
    "            for iusv in range(ilen):\n",
    "                if (ds_usv.time[iusv] < orbit_time) or (ds_usv.time[iusv] > orbit_time2):\n",
    "                    continue\n",
    "                pts = np.array([ds_usv.lon[iusv], ds_usv.lat[iusv]])\n",
    "                #        pts = np.array([ds_usv.lon[iusv]+360, ds_usv.lat[iusv]])\n",
    "                tree.query(pts, k=1)\n",
    "                i = tree.query(pts)[1]\n",
    "                rdist = tree.query(pts)[0]\n",
    "                # don't use matchups more than 25 km away\n",
    "                if rdist > .25:\n",
    "                    continue\n",
    "                # use .where to find the original indices of the matched data point\n",
    "                # find by matching sss and lat, just randomly chosen variables, you could use any\n",
    "                result = np.where((ds.tb == ds_drop.tb[i].data) & (ds.lat == ds_drop.lat[i].data))\n",
    "                listOfCoordinates = list(zip(result[0], result[1]))\n",
    "                if len(listOfCoordinates) == 0:\n",
    "                    continue\n",
    "                ii, jj = listOfCoordinates[0][0], listOfCoordinates[0][1]\n",
    "                deltaTa = ((ds_usv.time[iusv] - ds.time[ii]).data) / np.timedelta64(1, 'm')\n",
    "                if np.abs(deltaTa) < np.abs(ds_usv['insitu.dtime'][iusv].data):\n",
    "                    ds_usv['insitu.dtime'][iusv] = deltaTa\n",
    "                    ds_usv.amsr2_name[iusv] = file\n",
    "                    ds_usv.amsr2_dist[iusv] = rdist\n",
    "                    ds_usv.amsr2_scan[iusv] = ii\n",
    "                    ds_usv.amsr2_cell[iusv] = jj\n",
    "\n",
    "        usv_day += np.timedelta64(1,'D')\n",
    "#    df = xr.DataArray(file_save,name='filenames')\n",
    "    ds_usv = ds_usv.rename({'TEMP_CTD_MEAN':'insitu.sea_surface_temperature','TEMP_CTD_STDDEV':'insitu.sst_uncertainty',\n",
    "                             'TEMP_AIR_MEAN':'insitu.air_temperature','VWND_MEAN':'insitu.vwnd','UWND_MEAN':'insitu.uwnd',\n",
    "                             'WAVE_SIGNIFICANT_HEIGHT':'insitu.sig_wave_height','SAL_MEAN':'insitu.salinity','CHLOR_MEAN':'insitu.chlor',\n",
    "                             'BARO_PRES_MEAN':'insitu.baro_pres','RH_MEAN':'insitu.rel_humidity','GUST_WND_MEAN':'insitu.gust_wind',\n",
    "                             'lat':'insitu.lat','lon':'insitu.lon','time':'insitu.time'})\n",
    "\n",
    "    ds_usv.to_netcdf(fileout)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
